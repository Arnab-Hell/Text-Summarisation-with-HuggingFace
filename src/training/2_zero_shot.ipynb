{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b10ed5",
   "metadata": {},
   "source": [
    "# Part 2 - Zero-shot summaries\n",
    "\n",
    "In this part we will use Hugging Face's high-level Pipeline API to create summaries with a pre-trained model. There are three main steps involved when you pass some text to a pipeline:\n",
    "\n",
    "1) The text is preprocessed into a format the model can understand.\n",
    "\n",
    "2) The preprocessed inputs are passed to the model.\n",
    "\n",
    "3) The predictions of the model are post-processed, so you can make sense of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b15df7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655b884cda30428a98d2f55510713dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3623f8379a9643d381940dcbc50213bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef34d5f90a27429e85fc913f6151f86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f39fa08a6114ad8bef97c8760f37798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad5e50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\.cache\\huggingface\\hub\n"
     ]
    }
   ],
   "source": [
    "from transformers import file_utils\n",
    "print(file_utils.default_cache_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881bf006",
   "metadata": {},
   "source": [
    "- Pipeline: This is a function provided by the Hugging Face transformers library to make it easy to apply different types of Natural Language Processing (NLP) tasks, such as text classification, translation, summarization, and so on. The function returns a ready-to-use pipeline object for the specified task.\n",
    "- \"summarization\": This is the first argument to the pipeline function and specifies the type of task you want the pipeline to perform. In this case, \"summarization\" means that the pipeline will be configured to summarize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8981c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wrapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf214e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442cefa",
   "metadata": {},
   "source": [
    "The h5py package is a Pythonic interface to the HDF5 binary data format. \n",
    "HDF5 lets you store huge amounts of numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d1ef7",
   "metadata": {},
   "source": [
    "This line of code allows us to see which model is being used by default. We can also find this information in the source code for pipelines:https://github.com/huggingface/transformers/blob/master/src/transformers/pipelines/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23c9993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sshleifer/distilbart-cnn-12-6'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.model.config.__getattribute__('_name_or_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c21726",
   "metadata": {},
   "source": [
    "The model for the standard summarisation task is https://huggingface.co/sshleifer/distilbart-cnn-12-6, which has been specifically trained on 2 datasets: https://huggingface.co/datasets/cnn_dailymail and https://huggingface.co/datasets/xsum. We will keep using this model, but if we wanted to use a different model we could easily do this by specifing it like below. All the models that are trained for summarisation can be viewed here: https://huggingface.co/models?pipeline_tag=summarization&sort=downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizer = pipeline(\"summarization\", model='facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a40b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "ref_summaries = list(df_test['summary'])\n",
    "texts = list(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc20d1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc122d7e",
   "metadata": {},
   "source": [
    "Testing the pipeline with an abstract from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "758aabb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Threefold $X$ has a unique anticanonical section which is a Jacobian K3 Kummer surface $S$ of Picard number 17 . We construct an infinite-order pseudo-automorphism $\\\\phi_X$ on $X$, induced by the complete linear system of a divisor of degree 13 .'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(texts[0], max_length=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4ba28",
   "metadata": {},
   "source": [
    "Running the pipeline over all 2,000 examples. Because this will take a while we print a counter to keep track of the progress. This should take around 50 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187429e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_summaries = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    candidate = summarizer(text, min_length=5, max_length=20)\n",
    "    candidate_summaries.append(candidate[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c569312",
   "metadata": {},
   "source": [
    "Saving the candidate summaries in case we want to investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"summaries/zero-shot-summaries.txt\", \"w\")\n",
    "for s in candidate_summaries:\n",
    "    file.write(s + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4613a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_summaries[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f8780",
   "metadata": {},
   "source": [
    "Calculating the ROUGE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f849be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rouge_scores(candidates, references):\n",
    "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
    "    result = {key: round(value.mid.fmeasure * 100, 1) for key, value in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_rouge_scores(candidate_summaries, ref_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa2755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
